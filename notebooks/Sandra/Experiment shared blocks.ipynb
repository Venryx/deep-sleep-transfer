{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Dense, Conv1D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0519 13:10:45.816254 15372 deprecation_wrapper.py:119] From C:\\Users\\sa6pr7\\Anaconda3\\envs\\mlbase\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_input_a = Input(shape=(3000,1))\n",
    "model_input_b = Input(shape=(3000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start block\n",
    "layers_start = {}\n",
    "layers_start['s1'] = keras.layers.ZeroPadding1D(padding=3)\n",
    "layers_start['s2'] = Conv1D(8,2)\n",
    "layers_start['s3'] = keras.layers.BatchNormalization()\n",
    "layers_start['s4'] = keras.layers.Activation('relu')\n",
    "layers_start['s5'] = keras.layers.ZeroPadding1D(padding=1)\n",
    "layers_start['s6'] = keras.layers.MaxPooling1D(pool_size=3, strides=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv block\n",
    "layers_a = {}\n",
    "layers_a['a1'] = Conv1D(16,1, strides=1)\n",
    "layers_a['a2'] = keras.layers.BatchNormalization()\n",
    "\n",
    "layers_b = {}\n",
    "layers_b['b1'] = Conv1D(8,1)\n",
    "layers_b['b2'] = keras.layers.BatchNormalization()\n",
    "layers_b['b3'] = keras.layers.Activation('relu')\n",
    "layers_b['b4'] = Conv1D(8,3, padding='same',)\n",
    "layers_b['b5'] = keras.layers.BatchNormalization()\n",
    "layers_b['b6'] = keras.layers.Activation('relu')\n",
    "layers_b['b7'] = Conv1D(16,1)\n",
    "layers_b['b8'] = keras.layers.BatchNormalization()\n",
    "\n",
    "layers_c = {}\n",
    "layers_c['c2'] = keras.layers.Activation('relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_a1 = 0\n",
    "for i, layer in enumerate(layers_start.values()):\n",
    "    if i == 0:\n",
    "        x_a1 = layer(model_input_a)\n",
    "    else:\n",
    "        x_a1 = layer(x_a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_block shortcut line\n",
    "x_a_short = 0\n",
    "for i, layer in enumerate(layers_a.values()):\n",
    "    if i == 0:\n",
    "        x_a_short = layer(x_a1)\n",
    "    else:\n",
    "        x_a_short = layer(x_a_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_a_long = 0\n",
    "for i, layer in enumerate(layers_b.values()):\n",
    "    if i == 0:\n",
    "        x_a_long = layer(x_a1)\n",
    "    else:\n",
    "        x_a_long = layer(x_a_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_a_combined = keras.layers.add([x_a_short, x_a_long])\n",
    "for layer in layers_c.values():\n",
    "    x_a_combined = layer(x_a_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Dense(1, activation='sigmoid')(x_a_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=model_input_a, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0519 13:33:36.319839 15372 deprecation_wrapper.py:119] From C:\\Users\\sa6pr7\\Anaconda3\\envs\\mlbase\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0519 13:33:36.357597 15372 deprecation_wrapper.py:119] From C:\\Users\\sa6pr7\\Anaconda3\\envs\\mlbase\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0519 13:33:36.357597 15372 deprecation.py:323] From C:\\Users\\sa6pr7\\Anaconda3\\envs\\mlbase\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding1d_3 (ZeroPadding1D (None, 3006, 1)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 3005, 8)      24          zero_padding1d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 3005, 8)      32          conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 3005, 8)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding1d_4 (ZeroPadding1D (None, 3007, 8)      0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 1503, 8)      0           zero_padding1d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 1503, 8)      72          max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 1503, 8)      32          conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 1503, 8)      0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1503, 8)      200         activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 1503, 8)      32          conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 1503, 8)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 1503, 16)     144         max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 1503, 16)     144         activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 1503, 16)     64          conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 1503, 16)     64          conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 1503, 16)     0           batch_normalization_27[0][0]     \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 1503, 16)     0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1503, 1)      17          activation_23[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 825\n",
      "Trainable params: 713\n",
      "Non-trainable params: 112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_a = Input(shape=(3000,1))\n",
    "model_input_b = Input(shape=(3000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = []\n",
    "model_inputs.append(model_input_a)\n",
    "model_inputs.append(model_input_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start block\n",
    "layers_start = {}\n",
    "layers_start['s1'] = keras.layers.ZeroPadding1D(padding=3)\n",
    "layers_start['s2'] = Conv1D(8,2)\n",
    "layers_start['s3'] = keras.layers.BatchNormalization()\n",
    "layers_start['s4'] = keras.layers.Activation('relu')\n",
    "layers_start['s5'] = keras.layers.ZeroPadding1D(padding=1)\n",
    "layers_start['s6'] = keras.layers.MaxPooling1D(pool_size=3, strides=2)\n",
    "\n",
    "# conv block\n",
    "layers_a = {}\n",
    "layers_a['a1'] = Conv1D(16,1, strides=1)\n",
    "layers_a['a2'] = keras.layers.BatchNormalization()\n",
    "\n",
    "layers_b = {}\n",
    "layers_b['b1'] = Conv1D(8,1)\n",
    "layers_b['b2'] = keras.layers.BatchNormalization()\n",
    "layers_b['b3'] = keras.layers.Activation('relu')\n",
    "layers_b['b4'] = Conv1D(8,3, padding='same',)\n",
    "layers_b['b5'] = keras.layers.BatchNormalization()\n",
    "layers_b['b6'] = keras.layers.Activation('relu')\n",
    "layers_b['b7'] = Conv1D(16,1)\n",
    "layers_b['b8'] = keras.layers.BatchNormalization()\n",
    "\n",
    "layers_c = {}\n",
    "layers_c['c2'] = keras.layers.Activation('relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs = []\n",
    "\n",
    "for model_input in model_inputs:\n",
    "    x_a1 = 0\n",
    "    for i, layer in enumerate(layers_start.values()):\n",
    "        if i == 0:\n",
    "            x_a1 = layer(model_input_a)\n",
    "        else:\n",
    "            x_a1 = layer(x_a1)\n",
    "            \n",
    "    # conv_block shortcut line\n",
    "    x_a_short = 0\n",
    "    for i, layer in enumerate(layers_a.values()):\n",
    "        if i == 0:\n",
    "            x_a_short = layer(x_a1)\n",
    "        else:\n",
    "            x_a_short = layer(x_a_short)\n",
    "    \n",
    "    x_a_long = 0\n",
    "    for i, layer in enumerate(layers_b.values()):\n",
    "        if i == 0:\n",
    "            x_a_long = layer(x_a1)\n",
    "        else:\n",
    "            x_a_long = layer(x_a_long)\n",
    "    \n",
    "    x_a_combined = keras.layers.add([x_a_short, x_a_long])\n",
    "    for layer in layers_c.values():\n",
    "        x_a_combined = layer(x_a_combined)\n",
    "        \n",
    "    model_outputs.append(x_a_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_vector = keras.layers.concatenate(model_outputs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'activation_31/Relu:0' shape=(?, 1503, 16) dtype=float32>,\n",
       " <tf.Tensor 'activation_31_1/Relu:0' shape=(?, 1503, 16) dtype=float32>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 3000, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding1d_7 (ZeroPadding1D (None, 3006, 1)      0           input_3[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 3005, 8)      24          zero_padding1d_7[0][0]           \n",
      "                                                                 zero_padding1d_7[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 3005, 8)      32          conv1d_37[0][0]                  \n",
      "                                                                 conv1d_37[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 3005, 8)      0           batch_normalization_36[0][0]     \n",
      "                                                                 batch_normalization_36[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding1d_8 (ZeroPadding1D (None, 3007, 8)      0           activation_28[0][0]              \n",
      "                                                                 activation_28[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1503, 8)      0           zero_padding1d_8[0][0]           \n",
      "                                                                 zero_padding1d_8[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 1503, 8)      72          max_pooling1d_4[0][0]            \n",
      "                                                                 max_pooling1d_4[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1503, 8)      32          conv1d_39[0][0]                  \n",
      "                                                                 conv1d_39[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 1503, 8)      0           batch_normalization_38[0][0]     \n",
      "                                                                 batch_normalization_38[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 1503, 8)      200         activation_29[0][0]              \n",
      "                                                                 activation_29[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 1503, 8)      32          conv1d_40[0][0]                  \n",
      "                                                                 conv1d_40[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 1503, 8)      0           batch_normalization_39[0][0]     \n",
      "                                                                 batch_normalization_39[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1503, 16)     144         max_pooling1d_4[0][0]            \n",
      "                                                                 max_pooling1d_4[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 1503, 16)     144         activation_30[0][0]              \n",
      "                                                                 activation_30[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1503, 16)     64          conv1d_38[0][0]                  \n",
      "                                                                 conv1d_38[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 1503, 16)     64          conv1d_41[0][0]                  \n",
      "                                                                 conv1d_41[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 1503, 16)     0           batch_normalization_37[0][0]     \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 1503, 16)     0           batch_normalization_37[1][0]     \n",
      "                                                                 batch_normalization_40[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 1503, 16)     0           add_9[0][0]                      \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1503, 32)     0           activation_31[0][0]              \n",
      "                                                                 activation_31[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1503, 1)      33          concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 841\n",
      "Trainable params: 729\n",
      "Non-trainable params: 112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "predictions = Dense(1, activation='sigmoid')(merged_vector)\n",
    "model = Model(inputs=model_inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
